{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import datetime \n",
    "import pytz\n",
    "from pytz import timezone\n",
    "import tarfile\n",
    "from numpy import load\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "import h5py\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import Birch\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File('sound_data_improved.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = h5['sound_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a subsample of 10000 points from one sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for sensor id (sonycnode-b827ebc178d2.sonyc first, just to test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b827ebc178d2_data = d[(d['sensor_id'] == b'sonycnode-b827ebc178d2.sonyc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b827ebc178d2_indices = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559361616.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b827ebc178d_data[0]['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1423048"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b827ebc178d2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array with all feature vectors pertaining to a specific sensor, then array with timestamps corresponding to vector\n",
    "# b827ebc178d2_data = []\n",
    "# b827ebc178d2_timestamps = []\n",
    "# b827ebc178d2_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3388858):\n",
    "#     if d[i,'sensor_id'] == b'sonycnode-b827ebc178d2.sonyc':\n",
    "#         b827ebc178d2_data.append(d[i, 'feature_vector'])\n",
    "#         b827ebc178d2_timestamps.append(d[i, 'timestamp'])\n",
    "#         b827ebc178d2_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "b827ebc178d2_sample_nums = np.random.choice(range(len(b827ebc178d2_data)), 10000, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.zeros(len(b827ebc178d2_data)).astype('bool')\n",
    "index[b827ebc178d2_sample_nums] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "b827ebc178d2_sampled_data = b827ebc178d2_data[index]['feature_vector']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating subsample of 10000 points from all four sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3388858"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_nums = np.random.choice(range(d.shape[0]), 10000, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3388858,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index = np.zeros(d.shape[0]).astype('bool')\n",
    "all_index[sample_nums] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sensor_data = d[all_index]['feature_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sensor_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering on 45 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_45 = sklearnPCA(45)\n",
    "#should I fit and transform on just one sensor or all of the feature vectors?\n",
    "projected_45 = pca_45.fit_transform(d['feature_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projected_tsne_45 = TSNE(n_components=2).fit_transform(all_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_assignments(num_clusters):\n",
    "    mbk = MiniBatchKMeans(n_clusters=num_clusters, random_state=0)\n",
    "    mbk.fit(projected_45[all_index])\n",
    "    #have to fix\n",
    "    cluster_indices = mbk.predict(pca_45.fit_transform(b827ebc178d2_sampled_data))\n",
    "    return cluster_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_indices(data_arr):\n",
    "    count = 0\n",
    "    idx_arr = np.empty(len(data_arr))\n",
    "#     for point in range(data_arr.shape[0]):\n",
    "    for point in data_arr:\n",
    "#         idx = stats.mode(np.where(d['feature_vector']==data_arr[point])[0])[0]\n",
    "        #Have to do mode because matches in projected_45 covered almost a whole row, but in some cases shifted a little\n",
    "        idx_arr[count] = stats.mode(np.where(d['feature_vector']==point)[0])[0]\n",
    "        count += 1\n",
    "    return idx_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot timestamp vs frequency of cluster (for each cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_cluster_assignments(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = get_data_indices(b827ebc178d2_sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b827ebc178d2_sampled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamps(idx_arr):\n",
    "    timestamp_arr = []\n",
    "    for idx in idx_arr:\n",
    "        timestamp_arr.append(d[idx, 'timestamp'])\n",
    "    return timestamp_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_timestamps = get_timestamps(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cluster_timestamps, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clustering_1",
   "language": "python",
   "name": "clustering_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
