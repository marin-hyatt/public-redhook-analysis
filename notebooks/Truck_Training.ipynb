{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "import sys\n",
    "sys.path.insert(1, '../modules')\n",
    "import data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in \\\n",
    "    os.listdir('/green-projects/project-sonyc_redhook/workspace/share/redhook-analysis/output/embeddings'):\n",
    "        for file in os.listdir\\\n",
    "        ('/green-projects/project-sonyc_redhook/workspace/share/redhook-analysis/output/embeddings/' + folder):\n",
    "            timestamps.append(file.split('.')[0])\n",
    "            data = \\\n",
    "            np.load('/green-projects/project-sonyc_redhook/workspace/share/redhook-analysis/output/embeddings/'\\\n",
    "                    + folder + '/' + file)\n",
    "            emb = data['embedding']\n",
    "            embedding_list.append(emb)\n",
    "            data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(embedding):\n",
    "    embedding_mean = np.mean(embedding, axis=0)\n",
    "    embedding_std = np.std(embedding, axis=0)\n",
    "    embedding_max = np.amax(embedding, axis=0)\n",
    "    embedding_min = np.amin(embedding, axis=0)\n",
    "    embedding_summary = np.concatenate((embedding_mean, embedding_max, embedding_min, embedding_std))\n",
    "    return embedding_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate_embeddings_train(embedding_list):\n",
    "#     print(embedding_list.shape)\n",
    "\n",
    "\n",
    "    expanded_embedding_list = \\\n",
    "    np.reshape(embedding_list, (embedding_list.shape[0]*embedding_list.shape[1], 512))\n",
    "    \n",
    "    #should be something like (28937, 512)\n",
    "#     print(expanded_embedding_list.shape)\n",
    "    \n",
    "    pca_45 = sklearnPCA(45)\n",
    "    pca_45.fit(expanded_embedding_list)\n",
    "    \n",
    "    embedding_list = np.asarray([pca_45.transform(embedding) for embedding in embedding_list])\n",
    "    \n",
    "    #should be something like (1523, 19, 45)\n",
    "#     print(embedding_list.shape)\n",
    "    \n",
    "    embedding_summaries = np.asarray([get_summary(embedding) for embedding in embedding_list])\n",
    "\n",
    "#     print(embedding_summaries.shape)\n",
    "    \n",
    "    return(embedding_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate_embeddings_test(embedding_list):\n",
    "#     print(embedding_list.shape)\n",
    "\n",
    "\n",
    "    expanded_embedding_list = \\\n",
    "    np.reshape(embedding_list, (embedding_list.shape[0]*embedding_list.shape[1], 512))\n",
    "    \n",
    "    #should be something like (28937, 512)\n",
    "#     print(expanded_embedding_list.shape)\n",
    "    \n",
    "    pca_45.fit(expanded_embedding_list)\n",
    "    \n",
    "    embedding_list = np.asarray([pca_45.transform(embedding) for embedding in embedding_list])\n",
    "    \n",
    "    #should be something like (1523, 19, 45)\n",
    "#     print(embedding_list.shape)\n",
    "    \n",
    "    embedding_summaries = np.asarray([get_summary(embedding) for embedding in embedding_list])\n",
    "\n",
    "#     print(embedding_summaries.shape)\n",
    "    \n",
    "    return(embedding_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining embeddings with timestamp label\n",
    "NOTE: 1523 is the accurate number of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.asarray(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 180)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_summaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_embedding_summaries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(timestamps)):\n",
    "    labeled_embedding_summaries.append([timestamps[i], embedding_summaries[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_embedding_summaries = np.asarray([[int(timestamp), embedding] for [timestamp, embedding] in labeled_embedding_summaries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 2)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_embedding_summaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573060932"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_embedding_summaries[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_embedding_summaries[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_sorted = np.asarray(sorted(labeled_embedding_summaries, key=lambda tup: tup[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide annotations by day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Y list of classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/green-projects/project-sonyc_redhook/workspace/share/redhook-analysis/output/annotation_list.pickle', \"rb\") as f:\n",
    "       annotation_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1538"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list = [(int(timestamp), annotation) for (timestamp, annotation) in annotation_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1573060932, 'n')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting timestamps that aren't in labeled_embedding_summaries, so both arrays have the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_cut = []\n",
    "for annotation in annotation_list:\n",
    "    if annotation[0] in labeled_embedding_summaries[:,0]:\n",
    "        annotation_list_cut.append(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1523"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotation_list_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1573063463, 'n')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_list_cut[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort annotation list by timestamp, then filter out anything that's not a yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_sorted = sorted(annotation_list_cut, key=lambda tup: tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1573060932, 'n')"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_list_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_sorted = \\\n",
    "np.asarray([annotation for annotation in annotation_list_sorted if (annotation[1] == 'y' or annotation[1] == 'n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1509"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotation_list_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1573060932', '1573061031', '1573061130', ..., '1573852939',\n",
       "       '1573853129', '1573853688'], dtype='<U21')"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_list_sorted[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1509 is the number of annotations excluding \"maybes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_day = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_list = [6, 7, 8, 9, 10, 11, 12, 13, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_day = day_list[0]\n",
    "for day in day_list:\n",
    "#     print(day)\n",
    "    i = 0\n",
    "    current_day_list = []\n",
    "#     while data.convert_timestamps(annotation_list_sorted[i][0]).day == day:\n",
    "#         current_day = data.convert_timestamps(annotation_list_sorted[i][0]).day\n",
    "#         current_day_list.append(annotation_list_sorted[i])\n",
    "#         i += 1\n",
    "    for annotation in annotation_list_sorted:\n",
    "        if data.convert_timestamps(annotation[0]).day == day:\n",
    "            current_day_list.append(annotation)\n",
    "        \n",
    "    annotation_list_day.append(current_day_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_day = np.asarray(annotation_list_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_day_list)\n",
    "len(annotation_list_day[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_list_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of annotations grouped by day!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting embeddings by day, filtered to make sure we only have embeddings corresponding to yes/no annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_day = []\n",
    "timestamps_day = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in \\\n",
    "    os.listdir('/green-projects/project-sonyc_redhook/workspace/share/redhook-analysis/output/embeddings'):\n",
    "    day_arr = []\n",
    "    day_time_arr = []\n",
    "    for file in os.listdir\\\n",
    "        ('/green-projects/project-sonyc_redhook/workspace/share/redhook-analysis/output/embeddings/' + folder):\n",
    "#         print(int(file.split('.')[0]))\n",
    "        if file.split('.')[0] in annotation_list_sorted[:,0]:\n",
    "            day_time_arr.append(file.split('.')[0])\n",
    "            data = \\\n",
    "            np.load('/green-projects/project-sonyc_redhook/workspace/share/redhook-analysis/output/embeddings/'\\\n",
    "                    + folder + '/' + file)\n",
    "            emb = data['embedding'] \n",
    "            day_arr.append(emb)\n",
    "            data.close()\n",
    "    timestamps_day.append(np.asarray(day_time_arr))\n",
    "    embeddings_day.append(np.asarray(day_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_day = np.asarray(embeddings_day)\n",
    "timestamps_day = np.asarray(timestamps_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_embeddings = 1509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=9)\n",
    "kf.get_n_splits(embeddings_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every train/test split, run PCA, get embedding summaries, use standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1 2 3 4 5 6 7 8] TEST: [0]\n",
      "(88, 19, 512)\n",
      "(88, 180)\n",
      "TRAIN: [0 2 3 4 5 6 7 8] TEST: [1]\n",
      "(199, 19, 512)\n",
      "(199, 180)\n",
      "TRAIN: [0 1 3 4 5 6 7 8] TEST: [2]\n",
      "(160, 19, 512)\n",
      "(160, 180)\n",
      "TRAIN: [0 1 2 4 5 6 7 8] TEST: [3]\n",
      "(107, 19, 512)\n",
      "(107, 180)\n",
      "TRAIN: [0 1 2 3 5 6 7 8] TEST: [4]\n",
      "(115, 19, 512)\n",
      "(115, 180)\n",
      "TRAIN: [0 1 2 3 4 6 7 8] TEST: [5]\n",
      "(182, 19, 512)\n",
      "(182, 180)\n",
      "TRAIN: [0 1 2 3 4 5 7 8] TEST: [6]\n",
      "(190, 19, 512)\n",
      "(190, 180)\n",
      "TRAIN: [0 1 2 3 4 5 6 8] TEST: [7]\n",
      "(215, 19, 512)\n",
      "(215, 180)\n",
      "TRAIN: [0 1 2 3 4 5 6 7] TEST: [8]\n",
      "(253, 19, 512)\n",
      "(253, 180)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(embeddings_day):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = embeddings_day[train_index], embeddings_day[test_index]\n",
    "    y_train, y_test = annotation_list_day[train_index], annotation_list_day[test_index]\n",
    "    \n",
    "    total_train= []\n",
    "    for day in X_train:\n",
    "        for embedding in day:\n",
    "            total_train.append(embedding)\n",
    "     \n",
    "    total_train = np.asarray(total_train)\n",
    "    \n",
    "    total_train_annotations = []\n",
    "    for day in y_train:\n",
    "        for annotation in day:\n",
    "            total_train_annotations.append(annotation[1])\n",
    "            \n",
    "    total_train_annotations = np.asarray(total_train_annotations)\n",
    "    \n",
    "    #manipulate embeddings for each X_train\n",
    "    expanded_total_train = \\\n",
    "    np.reshape(total_train, (total_train.shape[0]*total_train.shape[1], 512))\n",
    "    \n",
    "    pca_45 = sklearnPCA(45)\n",
    "    pca_45.fit(expanded_total_train)\n",
    "    \n",
    "    total_train = np.asarray([pca_45.transform(embedding) for embedding in total_train])\n",
    "\n",
    "    total_train_summaries = np.asarray([get_summary(embedding) for embedding in total_train])\n",
    "\n",
    "    #standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(total_train_summaries)\n",
    "    total_train_scaler = scaler.transform(total_train_summaries)\n",
    "\n",
    "    #random forest on training data\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(total_train_scaler, total_train_annotations)\n",
    "    \n",
    "    #now apply to test data!\n",
    "    test = np.asarray(X_test[0])\n",
    "    print(test.shape)\n",
    "    \n",
    "    #manipulate embeddings for each X_test\n",
    "    expanded_test = \\\n",
    "    np.reshape(test, (test.shape[0]*test.shape[1], 512))\n",
    "    \n",
    "    test = np.asarray([pca_45.transform(embedding) for embedding in test])\n",
    "\n",
    "    test_summaries = np.asarray([get_summary(embedding) for embedding in test])\n",
    "\n",
    "    print(test_summaries.shape)\n",
    "    \n",
    "    #standard scaler on test data\n",
    "    test_scaler = scaler.transform(test_summaries)\n",
    "    \n",
    "    #random forest on test data\n",
    "    predictions = clf.predict(test_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "truck_update",
   "language": "python",
   "name": "truck_update"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
