{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import datetime\n",
    "import pytz\n",
    "from pytz import timezone\n",
    "import tarfile\n",
    "from numpy import load\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "import h5py\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import Birch\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: sonycnode-b827eb491436.sonyc and sonycnode-b827ebc178d2.sonyc are the ones with the most coverage, filter\n",
    "#for those! Also, take 5 random samples from each cluster along with the neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File('sound_data_improved.hdf5', 'r')\n",
    "\n",
    "d = h5['sound_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_sensor_mask = (d['sensor_id'] == b'sonycnode-b827ebc178d2.sonyc') | (d['sensor_id'] == b'sonycnode-b827eb491436.sonyc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_middle = d[middle_sensor_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_nums = np.random.choice(range(d_middle.shape[0]), 10000, replace=False)\n",
    "\n",
    "index = np.zeros(d_middle.shape[0]).astype('bool')\n",
    "index[sample_nums] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_106 = sklearnPCA(106)\n",
    "projected = pca_106.fit_transform(d_middle['feature_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_model(num_clusters):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_clusters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mbk.cluster_centers_ : array of shape (num_clusters, 45)\n",
    "        An array of the feature vectors for each centroid in each cluster.\n",
    "\n",
    "    \"\"\"\n",
    "    mbk = MiniBatchKMeans(n_clusters=num_clusters, random_state=0)\n",
    "    mbk.fit(projected[index])\n",
    "    return mbk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dt(timestamp):\n",
    "    \"\"\"\n",
    "    Converts a float timestamp to a datetime object.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    timestamp : float\n",
    "        A float representing the time.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dt : datetime object\n",
    "        A datetime object corresponding to the time represented by timestamp.\n",
    "    \"\"\"\n",
    "    dt = datetime.datetime.utcfromtimestamp(timestamp)\n",
    "    dt = pytz.UTC.localize(dt)\n",
    "    dt = dt.astimezone(pytz.timezone('US/Eastern'))\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_file_path(neighbors_file_path):\n",
    "    \"\"\"\n",
    "    Cuts a file name to start with the sensor name.\n",
    "    \"\"\"\n",
    "    return(neighbors_file_path[32:])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_neighbors_dataframe(num_clusters):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with the information (timestamp, filepath, etc) from five neighbors of each centroid in each\n",
    "    cluster the data is grouped into.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_clusters : int\n",
    "        Number of clusters to group the projected data into.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        pandas DataFrame listing information about each neighbor, including timestamp, filepath, the centroid it is\n",
    "        associated with, and the number of clusters the projected data is grouped into.\n",
    "    \"\"\"\n",
    "    cluster_assignments = get_cluster_model(num_clusters).predict(projected[index])\n",
    "    cluster_centers = get_cluster_model(num_clusters).cluster_centers_\n",
    "    centroid_cluster_assignments = get_cluster_model(num_clusters).predict(cluster_centers)\n",
    "\n",
    "    # print(centroid_cluster_assignments)\n",
    "    # print(len(cluster_centers))\n",
    "\n",
    "    centroids = []\n",
    "    centroid_num_arr = []\n",
    "    num_centroids = num_clusters*10*[num_clusters]\n",
    "    \n",
    "    is_neighbor = []\n",
    "    \n",
    "    #arrays for neighbors\n",
    "    timestamps = np.empty((num_clusters,10))\n",
    "    timestamps_orig = np.empty((num_clusters,10))\n",
    "    file_path = np.empty((num_clusters,10), dtype='S92')\n",
    "    # neighbor_file_path = []\n",
    "    sensor_id = np.empty((num_clusters,10), dtype='S60')\n",
    "    # neighbor_timestamps_dt = np.empty((64*5), dtype = datetime.datetime)\n",
    "    # print(neighbor_timestamps_dt.dtype)\n",
    "\n",
    "    for i,cluster_index in enumerate(range(num_clusters)):\n",
    "        #for each cluster center, query only the cluster it belongs to\n",
    "\n",
    "        #Filter out only the points belonging to one cluster\n",
    "        cluster_mask = (cluster_assignments==cluster_index)\n",
    "        cluster_test = projected[index][cluster_mask]\n",
    "\n",
    "        #Makes a list of the centroid of the cluster with length of the number of the points in the cluster\n",
    "        centroid_list = 10*[cluster_centers[cluster_index]]\n",
    "        centroids += centroid_list\n",
    "\n",
    "        #Makes a list of the cluster index with length of the number of the points in the cluster\n",
    "        centroid_num_list = 10*[cluster_index+1]\n",
    "        centroid_num_arr += centroid_num_list\n",
    "\n",
    "#         print(len(cluster_test))\n",
    "        nearest_neighbors = []\n",
    "        tree = spatial.KDTree(cluster_test)\n",
    "    #     print(cluster_centers[cluster_index])\n",
    "        nearest_neighbors = tree.query(cluster_centers[cluster_index], 5)[1]\n",
    "\n",
    "        #from only the points corresponding to a certain cluster in the 10000 subset of projected, apply the nearest\n",
    "        #neighbors mask to obtain the other characteristics like file path, timestamp, etc\n",
    "\n",
    "        neighbors_mask = np.zeros(len(cluster_test)).astype('bool')\n",
    "        neighbors_mask[np.sort(nearest_neighbors)] = True\n",
    "        is_neighbor += 5*['Y']\n",
    "        \n",
    "         #random sampling from cluster \n",
    "        random_nums = np.random.choice(range(cluster_test.shape[0]), 5, replace=False)\n",
    "        random_cluster_mask = np.zeros(cluster_test.shape[0]).astype('bool')\n",
    "        random_cluster_mask[random_nums] = True\n",
    "        is_neighbor += 5*['N']\n",
    "        \n",
    "        d_neighbors = d_middle[index][cluster_mask][neighbors_mask]\n",
    "        d_random = d_middle[index][cluster_mask][random_cluster_mask]\n",
    "        \n",
    "        timestamps_empty = np.empty((2, 5))\n",
    "        timestamps_empty[0] = d_neighbors['timestamp']\n",
    "        timestamps_empty[1] = d_random['timestamp']\n",
    "        timestamps[i] = (timestamps_empty.flatten())\n",
    "        \n",
    "        timestamps_orig_empty = np.empty((2, 5))\n",
    "        timestamps_orig_empty[0] = d_neighbors['timestamp_orig']\n",
    "        timestamps_orig_empty[1] = d_random['timestamp_orig']\n",
    "        timestamps_orig[i] = timestamps_orig_empty.flatten()\n",
    "        \n",
    "        file_path_empty = np.empty((2, 5), dtype='S92')\n",
    "        file_path_empty[0] = d_neighbors['file_path']\n",
    "        file_path_empty[1] = d_random['file_path']\n",
    "    #     print(neighbor_file_path_inner)\n",
    "        file_path[i] = file_path_empty.flatten()\n",
    "        \n",
    "        sensor_id_empty = np.empty((2, 5), dtype='S60')\n",
    "        sensor_id_empty[0] = d_neighbors['sensor_id']\n",
    "        sensor_id_empty[1] = d_random['sensor_id']\n",
    "        sensor_id[i] = sensor_id_empty.flatten()\n",
    "        \n",
    "        print('done with cluster ' + str(cluster_index))\n",
    "\n",
    "    timestamps_dt = [convert_to_dt(x) for x in timestamps.flatten()]\n",
    "    file_path_cut = [cut_file_path(x) for x in file_path.flatten()]\n",
    "    \n",
    "    print(len(is_neighbor))\n",
    "    \n",
    "    # Making the dataframe\n",
    "    df = pd.DataFrame(centroids)\n",
    "    df.insert(0, 'is_neighbor', is_neighbor, True)\n",
    "    df.insert(1, \"timestamp_orig\", timestamps_orig.flatten(), True)\n",
    "    df.insert(2, \"timestamp_dt\", timestamps_dt, True)\n",
    "    df.insert(3, \"sensor_id\", sensor_id.flatten(), True)\n",
    "    df.insert(4, \"file_path\", file_path_cut, True)\n",
    "    df.insert(5, \"centroid_num\", centroid_num_arr, True)\n",
    "    df.insert(6, \"num_clusters\", num_centroids, True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with cluster 0\n",
      "done with cluster 1\n",
      "done with cluster 2\n",
      "done with cluster 3\n",
      "done with cluster 4\n",
      "done with cluster 5\n",
      "done with cluster 6\n",
      "done with cluster 7\n",
      "done with cluster 8\n",
      "done with cluster 9\n",
      "done with cluster 10\n",
      "done with cluster 11\n",
      "done with cluster 12\n",
      "done with cluster 13\n",
      "done with cluster 14\n",
      "done with cluster 15\n",
      "done with cluster 16\n",
      "done with cluster 17\n",
      "done with cluster 18\n",
      "done with cluster 19\n",
      "done with cluster 20\n",
      "done with cluster 21\n",
      "done with cluster 22\n",
      "done with cluster 23\n",
      "done with cluster 24\n",
      "done with cluster 25\n",
      "done with cluster 26\n",
      "done with cluster 27\n",
      "done with cluster 28\n",
      "done with cluster 29\n",
      "done with cluster 30\n",
      "done with cluster 31\n",
      "done with cluster 32\n",
      "done with cluster 33\n",
      "done with cluster 34\n",
      "done with cluster 35\n",
      "done with cluster 36\n",
      "done with cluster 37\n",
      "done with cluster 38\n",
      "done with cluster 39\n",
      "done with cluster 40\n",
      "done with cluster 41\n",
      "done with cluster 42\n",
      "done with cluster 43\n",
      "done with cluster 44\n",
      "done with cluster 45\n",
      "done with cluster 46\n",
      "done with cluster 47\n",
      "done with cluster 48\n",
      "done with cluster 49\n",
      "done with cluster 50\n",
      "done with cluster 51\n",
      "done with cluster 52\n",
      "done with cluster 53\n",
      "done with cluster 54\n",
      "done with cluster 55\n",
      "done with cluster 56\n",
      "done with cluster 57\n",
      "done with cluster 58\n",
      "done with cluster 59\n",
      "done with cluster 60\n",
      "done with cluster 61\n",
      "done with cluster 62\n",
      "done with cluster 63\n",
      "640\n"
     ]
    }
   ],
   "source": [
    "df_2 = make_neighbors_dataframe(2 ** 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_neighbor</th>\n",
       "      <th>timestamp_orig</th>\n",
       "      <th>timestamp_dt</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>centroid_num</th>\n",
       "      <th>num_clusters</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>1.559518e+09</td>\n",
       "      <td>2019-06-02 19:31:45-04:00</td>\n",
       "      <td>b'sonycnode-b827ebc178d2.sonyc'</td>\n",
       "      <td>b'sonycnode-b827ebc178d2.sonyc/2019-06-02/19/1...</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>17.653128</td>\n",
       "      <td>3.403607</td>\n",
       "      <td>-0.457391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.009314</td>\n",
       "      <td>-0.038994</td>\n",
       "      <td>-0.091355</td>\n",
       "      <td>-0.115825</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>0.086923</td>\n",
       "      <td>-0.06943</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>-0.049835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>1.559693e+09</td>\n",
       "      <td>2019-06-04 19:55:20-04:00</td>\n",
       "      <td>b'sonycnode-b827ebc178d2.sonyc'</td>\n",
       "      <td>b'sonycnode-b827ebc178d2.sonyc/2019-06-04/19/1...</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>17.653128</td>\n",
       "      <td>3.403607</td>\n",
       "      <td>-0.457391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.009314</td>\n",
       "      <td>-0.038994</td>\n",
       "      <td>-0.091355</td>\n",
       "      <td>-0.115825</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>0.086923</td>\n",
       "      <td>-0.06943</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>-0.049835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>1.560626e+09</td>\n",
       "      <td>2019-06-15 15:19:10-04:00</td>\n",
       "      <td>b'sonycnode-b827ebc178d2.sonyc'</td>\n",
       "      <td>b'sonycnode-b827ebc178d2.sonyc/2019-06-15/15/1...</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>17.653128</td>\n",
       "      <td>3.403607</td>\n",
       "      <td>-0.457391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.009314</td>\n",
       "      <td>-0.038994</td>\n",
       "      <td>-0.091355</td>\n",
       "      <td>-0.115825</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>0.086923</td>\n",
       "      <td>-0.06943</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>-0.049835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>1.561209e+09</td>\n",
       "      <td>2019-06-22 09:17:31-04:00</td>\n",
       "      <td>b'sonycnode-b827ebc178d2.sonyc'</td>\n",
       "      <td>b'sonycnode-b827ebc178d2.sonyc/2019-06-22/09/1...</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>17.653128</td>\n",
       "      <td>3.403607</td>\n",
       "      <td>-0.457391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.009314</td>\n",
       "      <td>-0.038994</td>\n",
       "      <td>-0.091355</td>\n",
       "      <td>-0.115825</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>0.086923</td>\n",
       "      <td>-0.06943</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>-0.049835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>1.561616e+09</td>\n",
       "      <td>2019-06-27 02:21:17-04:00</td>\n",
       "      <td>b'sonycnode-b827ebc178d2.sonyc'</td>\n",
       "      <td>b'sonycnode-b827ebc178d2.sonyc/2019-06-27/02/1...</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>17.653128</td>\n",
       "      <td>3.403607</td>\n",
       "      <td>-0.457391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.009314</td>\n",
       "      <td>-0.038994</td>\n",
       "      <td>-0.091355</td>\n",
       "      <td>-0.115825</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>0.086923</td>\n",
       "      <td>-0.06943</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>-0.049835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_neighbor  timestamp_orig              timestamp_dt  \\\n",
       "0           Y    1.559518e+09 2019-06-02 19:31:45-04:00   \n",
       "1           Y    1.559693e+09 2019-06-04 19:55:20-04:00   \n",
       "2           Y    1.560626e+09 2019-06-15 15:19:10-04:00   \n",
       "3           Y    1.561209e+09 2019-06-22 09:17:31-04:00   \n",
       "4           Y    1.561616e+09 2019-06-27 02:21:17-04:00   \n",
       "\n",
       "                         sensor_id  \\\n",
       "0  b'sonycnode-b827ebc178d2.sonyc'   \n",
       "1  b'sonycnode-b827ebc178d2.sonyc'   \n",
       "2  b'sonycnode-b827ebc178d2.sonyc'   \n",
       "3  b'sonycnode-b827ebc178d2.sonyc'   \n",
       "4  b'sonycnode-b827ebc178d2.sonyc'   \n",
       "\n",
       "                                           file_path  centroid_num  \\\n",
       "0  b'sonycnode-b827ebc178d2.sonyc/2019-06-02/19/1...             1   \n",
       "1  b'sonycnode-b827ebc178d2.sonyc/2019-06-04/19/1...             1   \n",
       "2  b'sonycnode-b827ebc178d2.sonyc/2019-06-15/15/1...             1   \n",
       "3  b'sonycnode-b827ebc178d2.sonyc/2019-06-22/09/1...             1   \n",
       "4  b'sonycnode-b827ebc178d2.sonyc/2019-06-27/02/1...             1   \n",
       "\n",
       "   num_clusters          0         1         2  ...        96        97  \\\n",
       "0            64  17.653128  3.403607 -0.457391  ... -0.009764 -0.009314   \n",
       "1            64  17.653128  3.403607 -0.457391  ... -0.009764 -0.009314   \n",
       "2            64  17.653128  3.403607 -0.457391  ... -0.009764 -0.009314   \n",
       "3            64  17.653128  3.403607 -0.457391  ... -0.009764 -0.009314   \n",
       "4            64  17.653128  3.403607 -0.457391  ... -0.009764 -0.009314   \n",
       "\n",
       "         98        99       100       101       102      103       104  \\\n",
       "0 -0.038994 -0.091355 -0.115825  0.087878  0.086923 -0.06943  0.070162   \n",
       "1 -0.038994 -0.091355 -0.115825  0.087878  0.086923 -0.06943  0.070162   \n",
       "2 -0.038994 -0.091355 -0.115825  0.087878  0.086923 -0.06943  0.070162   \n",
       "3 -0.038994 -0.091355 -0.115825  0.087878  0.086923 -0.06943  0.070162   \n",
       "4 -0.038994 -0.091355 -0.115825  0.087878  0.086923 -0.06943  0.070162   \n",
       "\n",
       "        105  \n",
       "0 -0.049835  \n",
       "1 -0.049835  \n",
       "2 -0.049835  \n",
       "3 -0.049835  \n",
       "4 -0.049835  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1, 2, 3, 4])\n",
    "test_2 = np.array([5, 6, 7, 8])\n",
    "np.concatenate((test, test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_1 = np.empty((2, 3))\n",
    "flatten_test = np.array([5, 6, 7])\n",
    "f_1[0] = flatten_test\n",
    "f_2 = np.array([8, 9, 10])\n",
    "f_1[1] = f_2\n",
    "f_1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clustering_1",
   "language": "python",
   "name": "clustering_1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
