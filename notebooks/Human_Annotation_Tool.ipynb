{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import re\n",
    "from IPython.display import display, Audio\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv\\\n",
    "('/green-projects/project-sonyc_redhook/workspace/share/redhook-analysis/output/max_dataframe_cut.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>frame</th>\n",
       "      <th>actual_timestamp</th>\n",
       "      <th>area</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1573061868</td>\n",
       "      <td>648</td>\n",
       "      <td>1573061911</td>\n",
       "      <td>276490</td>\n",
       "      <td>0.988503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1573830164</td>\n",
       "      <td>72</td>\n",
       "      <td>1573830168</td>\n",
       "      <td>207648</td>\n",
       "      <td>0.995947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>1573830164</td>\n",
       "      <td>1518</td>\n",
       "      <td>1573830265</td>\n",
       "      <td>294148</td>\n",
       "      <td>0.969995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>1573830554</td>\n",
       "      <td>72</td>\n",
       "      <td>1573830558</td>\n",
       "      <td>103700</td>\n",
       "      <td>0.983073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1573830554</td>\n",
       "      <td>190</td>\n",
       "      <td>1573830566</td>\n",
       "      <td>122512</td>\n",
       "      <td>0.977682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  start_timestamp  frame  actual_timestamp    area  probability\n",
       "0          10       1573061868    648        1573061911  276490     0.988503\n",
       "1          32       1573830164     72        1573830168  207648     0.995947\n",
       "2          45       1573830164   1518        1573830265  294148     0.969995\n",
       "3          64       1573830554     72        1573830558  103700     0.983073\n",
       "4          70       1573830554    190        1573830566  122512     0.977682"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame(video_file, frame_number):\n",
    "    vid_obj = cv2.VideoCapture(video_file)\n",
    "    vid_obj.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    res, frame = vid_obj.read()\n",
    "    if res:\n",
    "        cropped_frame = frame[200:850, 1100:1750]\n",
    "        return cropped_frame\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File\\\n",
    "('/green-projects/project-sonyc_redhook/workspace/share/redhook-analysis/output/max_img.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_img']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(h5.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_img = h5['max_img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('start_timestamp', '<f8'), ('frame', '<i8'), ('actual_timestamp', '<f8'), ('area', '<f8'), ('probability', '<f8'), ('img', '<i8', (650, 650, 3))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = max_img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_timestamp = max_img[6000]['actual_timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actual_timestamps = []\n",
    "for idx in range(max_idx):\n",
    "    actual_timestamps.append(max_img[idx]['actual_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_timestamps = np.array(actual_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(actual_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the 0th element just in case there are multiple matches\n",
    "row = max_img[actual_timestamps == target_timestamp][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6000]),)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(actual_timestamps == target_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will eventually have list of wav files, named with the actual time, in an array\n",
    "#then we will use a boolean mask to only annotate the files with corresponding audio\n",
    "#will access the audio files using their timestamp, from the audio list (iloc? loc? boolean mask?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder in \\\n",
    "# os.listdir('/green-projects/project-sonyc_redhook/workspace/share/truck_audio/redhook_truck_audio/1s'):\n",
    "#     count = 0\n",
    "#     for file in os.listdir\\\n",
    "#     ('/green-projects/project-sonyc_redhook/workspace/share/truck_audio/redhook_truck_audio/1s/' + folder):\n",
    "#         count += 1\n",
    "#     print(folder)\n",
    "#     print(count)\n",
    "# start_timestamp = 1573584188\n",
    "# end_timestamp = 1574577560\n",
    "# for folder in \\\n",
    "#     os.listdir('/green-projects/project-sonyc_redhook/workspace/share/truck_audio/redhook_truck_audio/1s'):\n",
    "#         for file in os.listdir\\\n",
    "#         ('/green-projects/project-sonyc_redhook/workspace/share/truck_audio/redhook_truck_audio/1s/' + folder):\n",
    "#             audio_timestamp = int(file.split(\".\")[0])\n",
    "#             if(start_timestamp <= audio_timestamp):\n",
    "#                 start_ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_color(img):\n",
    "    \"\"\"\n",
    "    Switches the colors of an image from BGR format to RGB format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : ndarray\n",
    "        An array representing an image, of the shape (x, x, 3). The array is in BGR format. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    switched_img : ndarray\n",
    "        An array representing an image, of the shape (x, x, 3). The array is in RGB format.\n",
    "    \"\"\"\n",
    "    #cv2 images are in bgr order, need to convert to rgb\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img)):\n",
    "            rgb_arr = img[:][i][j]\n",
    "            #swapping r with b\n",
    "            rgb_arr[0], rgb_arr[2] = rgb_arr[2], rgb_arr[0]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_img(img_arr, start_timestamp, end_timestamp):\n",
    "    \"\"\"\n",
    "    Displays an interface for annotating images to indicate whether there is a truck or not. The function\n",
    "    then stores the annotations and the timestamp of the images in an array. The function loops \n",
    "    through the audio array and displays the corresponding image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_arr : array\n",
    "        Array containing the image array inside. The image array should be in the 5th column of img_arr.\n",
    "        \n",
    "    start_timestamp : timestamp\n",
    "        Timestamp to start the annotations.\n",
    "        \n",
    "    end_timestamp: timestamp\n",
    "        Timestamp to end the annotations\n",
    "    \"\"\"\n",
    "    with open('annotation_list.pickle', \"rb\") as f:\n",
    "        annotation_list = pickle.load(f)\n",
    "    \n",
    "    #loop through the folders in redhook_truck_audio, get folder and file name\n",
    "    for folder in \\\n",
    "    os.listdir('/green-projects/project-sonyc_redhook/workspace/share/truck_audio/redhook_truck_audio/1s'):\n",
    "        for file in os.listdir\\\n",
    "        ('/green-projects/project-sonyc_redhook/workspace/share/truck_audio/redhook_truck_audio/1s/' + folder):\n",
    "            audio_timestamp = int(file.split(\".\")[0])\n",
    "            if(start_timestamp <= audio_timestamp) and (audio_timestamp <= end_timestamp):\n",
    "                #use audio timestamp to get corresponding image \n",
    "                match_row = max_img[actual_timestamps == audio_timestamp][0]\n",
    "\n",
    "                #display img\n",
    "                plt.imshow(switch_color(match_row['img']))\n",
    "                plt.show()\n",
    "\n",
    "                #play 1 second clip of audio (for this simple indexing of the audio list to work, we need to make sure\n",
    "                #the audio list corresponds with the masked list)\n",
    "                print('Ten-second audio clip corresponding to the image')\n",
    "                display(Audio(filename=\\\n",
    "                '/green-projects/project-sonyc_redhook/workspace/share/truck_audio/redhook_truck_audio/10s/' + \\\n",
    "                folder + '/' + file))\n",
    "\n",
    "#                 clip = input(\"Press y if you would like to listen to the ten-second audio clip and n if not: \")\n",
    "\n",
    "#                 if clip == 'y':\n",
    "#                     print('Ten-second audio clip corresponding to the image')\n",
    "#                     display(Audio(filename=\\\n",
    "#                     '/green-projects/project-sonyc_redhook/workspace/share/truck_audio/redhook_truck_audio/10s/' + \\\n",
    "#                     folder + '/' + file))\n",
    "\n",
    "                #truck or no? not sure?\n",
    "                annotation = ''\n",
    "        \n",
    "                while(annotation != 'y' and annotation != 'n' and annotation != 'm'):\n",
    "                    annotation = input('Press y if the image and the audio show a truck, and n if not. '  + \\\n",
    "                                   'Press m if you are unsure: ')\n",
    "                \n",
    "                print('Annotation: ' + str(match_row['actual_timestamp']) + ', ' + annotation) \n",
    "                #add answer to annotation_list\n",
    "                annotation_list.append((match_row['actual_timestamp'], annotation))\n",
    "\n",
    "    with open('annotation_list.pickle', \"wb\") as f:\n",
    "        pickle.dump(annotation_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "annotate_img(max_img, 1573654526, 1573660843)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018\n"
     ]
    }
   ],
   "source": [
    "with open('annotation_list.pickle', \"rb\") as f:\n",
    "        print(len(pickle.load(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('annotation_list.pickle', \"rb\") as f:\n",
    "        for i in pickle.load(f):\n",
    "            if i[0] == 1573654526:\n",
    "                print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38065843621399176"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "185/486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2758\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for folder in \\\n",
    "    os.listdir('/green-projects/project-sonyc_redhook/workspace/share/truck_audio/redhook_truck_audio/1s'):\n",
    "        for file in os.listdir\\\n",
    "        ('/green-projects/project-sonyc_redhook/workspace/share/truck_audio/redhook_truck_audio/1s/' + folder):\n",
    "            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048.04"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.38 * 2758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "truck_update",
   "language": "python",
   "name": "truck_update"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
